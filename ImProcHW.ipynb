{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function calibrateCamera:\n",
      "\n",
      "calibrateCamera(...)\n",
      "    calibrateCamera(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs[, rvecs[, tvecs[, flags[, criteria]]]]) -> retval, cameraMatrix, distCoeffs, rvecs, tvecs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.calibrateCamera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line (img, rho, theta, color=(0,255,0)):\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(np.around(x0 + 1000*(-b)))   # Here i have used int() instead of rounding the decimal value, so 3.8 --> 3\n",
    "    y1 = int(np.around(y0 + 1000*(a)))    # But if you want to round the number, then use np.around() function, then 3.8 --> 4.0\n",
    "    x2 = int(np.around(x0 - 1000*(-b)))   # But we need integers, so use int() function after that, ie int(np.around(x))\n",
    "    y2 = int(np.around(y0 - 1000*(a)))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),color,2)\n",
    "    #print (rho, theta, color)\n",
    "\n",
    "# Given y, this function returns x from (rho, theta) line equation\n",
    "def x_from_y(rho, theta, y):\n",
    "    sin_t = np.sin(theta)\n",
    "    cos_t = np.cos(theta) \n",
    "\n",
    "    return ((rho / cos_t) - ((y * sin_t) / cos_t))\n",
    "\n",
    "# Given x, this function returns y from (rho, theta) line equation\n",
    "def y_from_x(rho, theta, x):\n",
    "    sin_t = np.sin(theta)\n",
    "    cos_t = np.cos(theta) \n",
    "\n",
    "    return (-((x * cos_t) / sin_t) + (rho / sin_t)) \n",
    "\n",
    "# Given a point and the rectangle, this function checks \n",
    "# if this point lies inside the rectangle\n",
    "def check_point(x, y, left_x, right_x, up_y, down_y):\n",
    "    if (left_x <= x) and (x <= right_x) and (up_y <= y) and (y <= down_y):\n",
    "        return (int(np.around(x)), int(np.around(y)))\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# A line which traverses some rectangle has two points of traversal.\n",
    "#\n",
    "# This function finds four possible traversal points and drops those of them \n",
    "# which are not inside the rectangle\n",
    "def get_traversal_points(rho, theta, left_x, right_x, up_y, down_y):      \n",
    "\n",
    "    #Find four possible points of traversal\n",
    "    up = (x_from_y(rho, theta, up_y), up_y)\n",
    "    right = (right_x, y_from_x(rho, theta, right_x))\n",
    "    down = (x_from_y(rho, theta, down_y), down_y)\n",
    "    left = (left_x, y_from_x(rho, theta, left_x))\n",
    "\n",
    "    #If point is inside, we add it to the list; otherwise we add None\n",
    "    intersect_points = list(map(lambda p: check_point(p[0], p[1], left_x, right_x, up_y, down_y), [up, right, down, left]))\n",
    "\n",
    "    #Drop all None values\n",
    "    #intersect_points = [point for point in intersect_points if point != None]\n",
    "    intersect_points = [down, up]\n",
    "\n",
    "    #Check if exactly two points were found\n",
    "    if len(intersect_points) != 2:\n",
    "        print('Error! len(intersect_points) != 2, intersect_points = {}'.format(intersect_points))\n",
    "        return None\n",
    "    else:\n",
    "        return intersect_points\n",
    "\n",
    "\n",
    "# Get the point of traversal for 'plus' and 'minus' lines\n",
    "# The order as follows in a way to obtain convenient trapezoid\n",
    "def get_vanishing_point(rho_1, theta_1, rho_2, theta_2):\n",
    "    k_1 = - np.cos(theta_1) / np.sin(theta_1)\n",
    "    m_1 = rho_1 / np.sin(theta_1)\n",
    "\n",
    "    k_2 = - np.cos(theta_2) / np.sin(theta_2)\n",
    "    m_2 = rho_2 / np.sin(theta_2)\n",
    "\n",
    "    x = (m_1 - m_2) / (k_1 - k_2)\n",
    "    y = (k_1 * m_2 - k_2 * m_1) / (k_1 - k_2)\n",
    "\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points = 0\n",
    "def CorrectPerspectiveDistortion (input_folder, filename, output_folder):\n",
    "    #Read the image\n",
    "    base = input_folder\n",
    "    im = cv2.imread(base + filename)\n",
    "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "    equ = cv2.equalizeHist(gray)\n",
    "    #ret, thresh = cv2.threshold(equ,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    winSize = 3\n",
    "    blured = cv2.GaussianBlur(equ, (winSize, winSize), 0)\n",
    "    edges = cv2.Canny(blured,100,220,apertureSize = 3, L2gradient=True)\n",
    "\n",
    "    cv2.imwrite(output_folder+'gray_'+filename, gray)\n",
    "    cv2.imwrite(output_folder+'equ_'+filename, equ)\n",
    "    cv2.imwrite(output_folder+'blured_'+filename, blured)\n",
    "    cv2.imwrite(output_folder+'edges_'+filename, edges)\n",
    "\n",
    "    height = im.shape[0]\n",
    "    width = im.shape[1]\n",
    "\n",
    "    img = im.copy()\n",
    "    rho_minus = 0\n",
    "    rho_plus = np.inf\n",
    "\n",
    "    eps = 0.01\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180 , int (min(im.shape[0], im.shape[1]) / 3.25))\n",
    "    #print (len(lines))\n",
    "    \n",
    "    red = (0, 0, 255)\n",
    "    \n",
    "    for line in lines:\n",
    "        for rho,theta in line:\n",
    "            draw_line (img, rho, theta)\n",
    "            if (theta > np.pi / 2 + eps and np.abs (rho) > np.abs (rho_minus)):\n",
    "                rho_minus = rho\n",
    "                theta_minus = theta\n",
    "            if (theta < np.pi / 2 - eps and rho < rho_plus):\n",
    "                rho_plus = rho\n",
    "                theta_plus = theta\n",
    "\n",
    "    \n",
    "    draw_line (img, rho_minus, theta_minus, red)\n",
    "    draw_line (img, rho_plus, theta_plus, red)\n",
    "\n",
    "    cv2.imwrite(output_folder+'houghlines_red._'+filename, img)\n",
    "\n",
    "\n",
    "    van_x, van_y = get_vanishing_point(rho_plus, theta_plus, rho_minus, theta_minus)\n",
    "\n",
    "    offset = 0\n",
    "    if van_y > 0:\n",
    "        low_y = van_y + 15 #A small offset to avoid infinite width of the vanishing point\n",
    "        offset = low_y\n",
    "    else:\n",
    "        low_y = 0\n",
    "\n",
    "    plus_down, plus_up = get_traversal_points(rho_plus, theta_plus, 0, width, low_y, height)\n",
    "    minus_down, minus_up = get_traversal_points(rho_minus, theta_minus, 0, width, low_y, height)\n",
    "\n",
    "    # Create a transform and apply it\n",
    "    from_points = np.float32([plus_down, plus_up, minus_up, minus_down])\n",
    "    init_width = int(np.around(minus_down[0] - plus_down[0]))\n",
    "\n",
    "    plus_down = (plus_down[0] + max(0, -plus_down[0]), plus_down[1])\n",
    "    minus_down = (plus_down[0] + init_width, minus_down[1])\n",
    "\n",
    "    to_points = np.float32([plus_down, (plus_down[0], plus_up[1]), (minus_down[0], minus_up[1]), minus_down])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(from_points, to_points)\n",
    "    input_corners = np.array([[(0, height), (0, plus_up[1]), (width, minus_up[1]), (width, height)]], dtype=float)\n",
    "\n",
    "    output_corners = cv2.perspectiveTransform(input_corners, M)\n",
    "\n",
    "    x_min = functools.reduce(lambda x,y: [min(x[0], y[0]), 0], output_corners[0])[0]\n",
    "    x_max = functools.reduce(lambda x,y: [max(x[0], y[0]), 0], output_corners[0])[0]\n",
    "    y_min = functools.reduce(lambda x,y: [0, min(x[1], y[1])], output_corners[0])[1]\n",
    "    y_max = functools.reduce(lambda x,y: [0, max(x[1], y[1])], output_corners[0])[1]\n",
    "\n",
    "    br_x = x_min\n",
    "    br_y = y_min\n",
    "\n",
    "    new_width = int(x_max - x_min)\n",
    "    new_height = int(y_max - y_min)\n",
    "\n",
    "    to_points = np.float32([(to_point[0] - br_x, to_point[1] - br_y) for to_point in to_points])\n",
    "    M_shifted = cv2.getPerspectiveTransform(from_points, to_points)\n",
    "\n",
    "    dst = cv2.warpPerspective(im, M_shifted, (new_width, new_height))\n",
    "    cv2.imwrite(output_folder+'transformed_'+filename, dst)\n",
    "    return from_points, im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'theta_minus' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-41c62723aff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorrectPerspectiveDistortion\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'test_images/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_images/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9abd73819a05>\u001b[0m in \u001b[0;36mCorrectPerspectiveDistortion\u001b[0;34m(input_folder, filename, output_folder)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdraw_line\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_minus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mdraw_line\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'theta_minus' referenced before assignment"
     ]
    }
   ],
   "source": [
    "test_points = 0\n",
    "for file in os.listdir('test_images'):\n",
    "    test_points, img = CorrectPerspectiveDistortion ('test_images/', file, 'output_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ad045e45c5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m A = np.array([\n\u001b[0;32m----> 3\u001b[0;31m              \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m              \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m       \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "t = test_points\n",
    "A = np.array([\n",
    "             [t[0][0], t[0][1], 0,       0,       t[0][0]**2,      t[0][0]*t[0][1]],\n",
    "             [t[1][0], t[1][1], 0,       0,       t[0][0]*t[1][0], t[0][0]*t[1][1]],\n",
    "             [t[2][0], t[1][1], 0,       0,       t[2][0]*t[3][0], t[1][1]*t[3][0]],\n",
    "             [t[3][0], t[0][1], 0,       0,       t[3][0]**2,      t[0][1]*t[3][0]],\n",
    "             [0,       0,       t[0][0], t[0][1], t[0][0]*t[0][1], t[0][1]**2     ],\n",
    "             [0,       0,       t[3][0], t[0][1], t[3][0]*t[0][1], t[0][1]**2     ]\n",
    "            ])\n",
    "b = np.array([[t[0][0]], [t[0][0]], [t[3][0]], [t[3][0]], [t[0][1]], [t[0][1]]])\n",
    "\n",
    "x0 = np.dot (np.linalg.inv(A), b).T[0]\n",
    "print (x0)\n",
    "\n",
    "M = np.array([[x0[0], x0[1], 0],\n",
    "               [x0[2], x0[3], 0],\n",
    "               [x0[4], x0[5], 1]\n",
    "              ])\n",
    "\n",
    "out = cv2.warpPerspective(img, M, (img.shape[0], img.shape[1]))\n",
    "cv2.imwrite('hi.png', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original code is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 600, 3)\n",
      "I am a good boy\n",
      "((-274.81872754898643, 900), (244.79652404785156, 0))\n",
      "((695.7419955522769, 900), (350.264404296875, 0))\n"
     ]
    }
   ],
   "source": [
    "# help(cv2.threshold)\n",
    "\n",
    "#Read the image\n",
    "base = './test_images/'\n",
    "im = cv2.imread(base + '4.jpg')\n",
    "gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "equ = cv2.equalizeHist(gray)\n",
    "#ret, thresh = cv2.threshold(equ,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "winSize = 3\n",
    "blured = cv2.GaussianBlur(equ, (winSize, winSize), 0)\n",
    "edges = cv2.Canny(blured,100,220,apertureSize = 3, L2gradient=True)\n",
    "\n",
    "\n",
    "\n",
    "#cv2.imshow('houghlines',im)\n",
    "cv2.imwrite(base+'gray.jpg', gray)\n",
    "cv2.imwrite(base+'equ.jpg', equ)\n",
    "cv2.imwrite(base+'blured.jpg', blured)\n",
    "cv2.imwrite(base+'edges.jpg', edges)\n",
    "\n",
    "#cv2.imwrite(base+'thresh.jpg', thresh)\n",
    "\n",
    "#A few changes to check git functionality\n",
    "print(im.shape)\n",
    "\n",
    "height = im.shape[0]\n",
    "width = im.shape[1]\n",
    "\n",
    "\n",
    "img = im.copy()\n",
    "rho_minus = 0\n",
    "rho_plus = np.inf\n",
    "\n",
    "rho_hor_max = 0\n",
    "hor_max_found = False\n",
    "rho_hor_min = im.shape[0]\n",
    "hor_min_found = False\n",
    "eps = 0.01\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180, int (min(im.shape[0], im.shape[1]) / 3.25))\n",
    "#print (lines)\n",
    "for line in lines:\n",
    "    for rho,theta in line:\n",
    "        if (theta > np.pi / 2 + eps and np.abs (rho) > np.abs (rho_minus)):\n",
    "            rho_minus = rho\n",
    "            theta_minus = theta\n",
    "        if (theta < np.pi / 2 - eps and rho < rho_plus):\n",
    "            rho_plus = rho\n",
    "            theta_plus = theta\n",
    "        if (np.abs (theta - np.pi / 2) < eps):\n",
    "            if (rho > rho_hor_max):\n",
    "                rho_hor_max = rho\n",
    "                hor_max_found = True\n",
    "            if (rho < rho_hor_min):\n",
    "                rho_hor_min = rho\n",
    "                hor_min_found = True\n",
    "        #draw_line (img, rho, theta)\n",
    "        \n",
    "red = (0, 0, 255)\n",
    "draw_line (img, rho_minus, theta_minus, red)\n",
    "draw_line (img, rho_plus, theta_plus, red)\n",
    "\n",
    "cv2.imwrite(base+'houghlines_red.jpg', img)\n",
    "\n",
    "\n",
    "# Get the point of traversal for 'plus' and 'minus' lines\n",
    "# The order as follows in a way to obtain convenient trapezoid\n",
    "\n",
    "van_x, van_y = get_vanishing_point(rho_plus, theta_plus, rho_minus, theta_minus)\n",
    "\n",
    "offset = 0\n",
    "if van_y > 0:\n",
    "    low_y = van_y + 15#(height - van_y) // 15\n",
    "    offset = low_y\n",
    "else:\n",
    "    low_y = 0\n",
    "    print('I am a good boy')\n",
    "\n",
    "plus_down, plus_up = get_traversal_points(rho_plus, theta_plus, 0, width, low_y, height)\n",
    "minus_down, minus_up = get_traversal_points(rho_minus, theta_minus, 0, width, low_y, height)\n",
    "\n",
    "print(plus_down, plus_up)\n",
    "print(minus_down, minus_up)\n",
    "\n",
    "# strip = im[:, plus_up[0]:minus_up[0]]\n",
    "# cv2.imwrite(base + 'strip.jpg', strip)\n",
    "\n",
    "#strip_edges = edges[:, plus_up[0]:minus_up[0]]\n",
    "\n",
    "#strip_img = strip.copy()\n",
    "\n",
    "# rho_hor_min = strip.shape[0]\n",
    "# hor_min_found = False\n",
    "# eps = 0.01\n",
    "# lines = cv2.HoughLines(strip_edges,1,np.pi/180, int (min(strip.shape[0], strip.shape[1]) / 2))\n",
    "\n",
    "# for line in lines:\n",
    "#     for rho,theta in line:\n",
    "#         if (np.abs (theta - np.pi / 2) < eps):\n",
    "#             if (rho < rho_hor_min):\n",
    "#                 rho_hor_min = rho\n",
    "#                 hor_min_found = True\n",
    "#         #draw_line (img, rho, theta)\n",
    "\n",
    "# if hor_min_found:\n",
    "#     draw_line (strip_img, rho_hor_min, np.pi / 2, red)\n",
    "# else:\n",
    "#     print('No roof was found!')\n",
    "#     rho_hor_min = 0\n",
    "    \n",
    "# cv2.imwrite(base+'strip_houghlines_red.jpg', strip_img)\n",
    "\n",
    "# crop_up = int(np.around(rho_hor_min))\n",
    "# crop_down = min(minus_down[1], plus_down[1])\n",
    "# print(crop_up, crop_down)\n",
    "\n",
    "# crop = im[crop_up:crop_down, :]\n",
    "# cv2.imwrite(base + 'cropped.jpg', crop)\n",
    "\n",
    "# Get the points of traversal for the cropped picture\n",
    "# crop_plus_down, crop_plus_up = get_traversal_points(rho_plus, theta_plus, 0, width, crop_up, crop_down)\n",
    "# crop_minus_up, crop_minus_down = get_traversal_points(rho_minus, theta_minus, 0, width, crop_up, crop_down)\n",
    "\n",
    "# crop_height, crop_width = crop.shape[0], crop.shape[1]\n",
    "\n",
    "# Create a transform and apply it\n",
    "from_points = np.float32([plus_down, plus_up, minus_up, minus_down])\n",
    "\n",
    "init_width = int(np.around(minus_down[0] - plus_down[0]))\n",
    "\n",
    "plus_down = (plus_down[0] + max(0, -plus_down[0]), plus_down[1])\n",
    "minus_down = (plus_down[0] + init_width, minus_down[1])\n",
    "\n",
    "to_points = np.float32([plus_down, (plus_down[0], plus_up[1]), (minus_down[0], minus_up[1]), minus_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-109.723625\n",
      "(2163.3307652783938, 559.7236251831055)\n",
      "((0.0, 900), (244.79652404785156, 0))\n",
      "[[-300, 900, 2163.3307652783938], [-300, 0, 2163.3307652783938], [300, 0, 2163.3307652783938], [300, 900, 2163.3307652783938]]\n",
      "[(-918.4891524719123, -2860.9859190374777), (-2395.361308715626, -8361.269364803042), (0.0, -8361.269364803042), (0.0, -2860.9859190374777)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.sqrt(width**2+height**2) * 2.\n",
    "print (van_y)\n",
    "is_dist = height/ 2 - van_y\n",
    "print (f, is_dist)\n",
    "sin_alpha = f / np.sqrt(f**2 + is_dist**2)\n",
    "cos_alpha = is_dist / np.sqrt(f**2 + is_dist**2)\n",
    "tilt_matrix = np.array([[1, 0, 0],\n",
    "                        [0, cos_alpha, -sin_alpha],\n",
    "                        [0, sin_alpha, cos_alpha]])\n",
    "shift_matrix = np.array([[1, 0, -width / 2 / f],\n",
    "                         [0, 1, 0],\n",
    "                         [0, 0, 1]])\n",
    "M = np.dot(tilt_matrix, shift_matrix)\n",
    "print (plus_down, plus_up)\n",
    "start = [\n",
    "    [-width/2, height, f],\n",
    "    [-width/2, 0, f],\n",
    "    #[plus_up[0], plus_up[1], f],\n",
    "    #[plus_down[0], plus_down[1], f],\n",
    "    [width/2, 0, f],\n",
    "    [width/2, height, f]\n",
    "]\n",
    "print (start)\n",
    "t_st = np.float32([(x[0],x[1]) for x in start])\n",
    "finish = []\n",
    "for x in start:\n",
    "    tmp = np.dot(M, np.transpose(x))\n",
    "    finish.append ((tmp[0]*f/tmp[2], tmp[1]*f/tmp[2]))\n",
    "print (finish)\n",
    "\n",
    "matr = cv2.getPerspectiveTransform(t_st, np.array([finish], dtype=np.float32))\n",
    "\n",
    "x_min = functools.reduce(lambda x,y: [min(x[0], y[0]), 0], finish)[0]\n",
    "x_max = functools.reduce(lambda x,y: [max(x[0], y[0]), 0], finish)[0]\n",
    "y_min = functools.reduce(lambda x,y: [0, min(x[1], y[1])], finish)[1]\n",
    "y_max = functools.reduce(lambda x,y: [0, max(x[1], y[1])], finish)[1]\n",
    "\n",
    "br_x = x_min / 2\n",
    "br_y = y_min\n",
    "\n",
    "new_width = int(x_max - x_min)\n",
    "new_height = int(y_max - y_min)\n",
    "\n",
    "to_points = np.float32([(to_point[0] - br_x, to_point[1] - br_y) for to_point in finish])\n",
    "M_shifted = cv2.getPerspectiveTransform(t_st, to_points)\n",
    "\n",
    "dst = cv2.warpPerspective(im, M_shifted, (new_width, new_height))\n",
    "cv2.imwrite(base+'transformed1.jpg', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.42320822e-01 -6.80528903e-01 -2.88294964e+00  1.10601318e+00\n",
      " -3.20327732e-03  1.17792411e-04]\n"
     ]
    }
   ],
   "source": [
    "t = from_points\n",
    "A = np.array([\n",
    "             [t[0][0], t[0][1], 0,       0,       -t[0][0]**2,      -t[0][0]*t[0][1]],\n",
    "             [t[1][0], t[1][1], 0,       0,       -t[0][0]*t[1][0], -t[0][0]*t[1][1]],\n",
    "             [t[2][0], t[1][1], 0,       0,       -t[2][0]*t[3][0], -t[1][1]*t[3][0]],\n",
    "             [t[3][0], t[0][1], 0,       0,       -t[3][0]**2,      -t[0][1]*t[3][0]],\n",
    "             [0,       0,       t[0][0], t[0][1], -t[0][0]*t[0][1], -t[0][1]**2     ],\n",
    "             [0,       0,       t[3][0], t[0][1], -t[3][0]*t[0][1], -t[0][1]**2     ]\n",
    "            ])\n",
    "b = np.array([[t[0][0]], [t[0][0]], [t[3][0]], [t[3][0]], [t[0][1]], [t[0][1]]])\n",
    "\n",
    "x0 = np.dot (np.linalg.inv(A), b).T[0]\n",
    "print (x0)\n",
    "\n",
    "M = np.array([[x0[0], x0[1], 0],\n",
    "               [x0[2], x0[3], 0],\n",
    "               [x0[4], x0[5], 1]\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-77f51f6f4a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplus_up\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminus_up\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moutput_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperspectiveTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_corners\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_corners\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    }
   ],
   "source": [
    "#M = cv2.getPerspectiveTransform(from_points, to_points)\n",
    "input_corners = np.array([[(0, height), (0, plus_up[1]), (width, minus_up[1]), (width, height)]], dtype=float)\n",
    "\n",
    "output_corners = cv2.perspectiveTransform(input_corners, M)\n",
    "print (output_corners)\n",
    "x_min = functools.reduce(lambda x,y: [min(x[0], y[0]), 0], output_corners[0])[0]\n",
    "x_max = functools.reduce(lambda x,y: [max(x[0], y[0]), 0], output_corners[0])[0]\n",
    "y_min = functools.reduce(lambda x,y: [0, min(x[1], y[1])], output_corners[0])[1]\n",
    "y_max = functools.reduce(lambda x,y: [0, max(x[1], y[1])], output_corners[0])[1]\n",
    "\n",
    "br_x = x_min\n",
    "br_y = y_min\n",
    "\n",
    "shift = np.array ([[1, 0, -br_x],\n",
    "                   [0, 1, -br_y],\n",
    "                   [0, 0, 1]])\n",
    "print (shift)\n",
    "\n",
    "new_width = int(x_max - x_min)\n",
    "new_height = int(y_max - y_min)\n",
    "\n",
    "#to_points = np.float32([(to_point[0] - br_x, to_point[1] - br_y) for to_point in to_points])\n",
    "M_shifted = np.dot (shift, M)\n",
    "\n",
    "#dst = cv2.warpPerspective(im, M_shifted, (max(init_width, width), height))\n",
    "dst = cv2.warpPerspective(im, M_shifted,  (new_width, new_height))\n",
    "print (dst.shape)\n",
    "cv2.imwrite(base+'transformed1.jpg', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function boundingRect:\n",
      "\n",
      "boundingRect(...)\n",
      "    boundingRect(points) -> retval\n",
      "    .   @brief Calculates the up-right bounding rectangle of a point set.\n",
      "    .   \n",
      "    .   The function calculates and returns the minimal up-right bounding rectangle for the specified point set.\n",
      "    .   \n",
      "    .   @param points Input 2D point set, stored in std::vector or Mat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.boundingRect)\n",
    "cv2.boundi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2048.2771567975346, 3350.274812135679)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min, x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2048.2771567975346, 0]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vanishing_point(rho_1, theta_1, rho_2, theta_2):\n",
    "    k_1 = - np.cos(theta_1) / np.sin(theta_1)\n",
    "    m_1 = rho_1 / np.sin(theta_1)\n",
    "    \n",
    "    k_2 = - np.cos(theta_2) / np.sin(theta_2)\n",
    "    m_2 = rho_2 / np.sin(theta_2)\n",
    "    \n",
    "    x = (m_1 - m_2) / (k_1 - k_2)\n",
    "    y = (k_1 * m_2 - k_2 * m_1) / (k_1 - k_2)\n",
    "    \n",
    "    return (x, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
