{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function threshold:\n",
      "\n",
      "threshold(...)\n",
      "    threshold(src, thresh, maxval, type[, dst]) -> retval, dst\n",
      "    .   @brief Applies a fixed-level threshold to each array element.\n",
      "    .   \n",
      "    .   The function applies fixed-level thresholding to a multiple-channel array. The function is typically\n",
      "    .   used to get a bi-level (binary) image out of a grayscale image ( #compare could be also used for\n",
      "    .   this purpose) or for removing a noise, that is, filtering out pixels with too small or too large\n",
      "    .   values. There are several types of thresholding supported by the function. They are determined by\n",
      "    .   type parameter.\n",
      "    .   \n",
      "    .   Also, the special values #THRESH_OTSU or #THRESH_TRIANGLE may be combined with one of the\n",
      "    .   above values. In these cases, the function determines the optimal threshold value using the Otsu's\n",
      "    .   or Triangle algorithm and uses it instead of the specified thresh.\n",
      "    .   \n",
      "    .   @note Currently, the Otsu's and Triangle methods are implemented only for 8-bit single-channel images.\n",
      "    .   \n",
      "    .   @param src input array (multiple-channel, 8-bit or 32-bit floating point).\n",
      "    .   @param dst output array of the same size  and type and the same number of channels as src.\n",
      "    .   @param thresh threshold value.\n",
      "    .   @param maxval maximum value to use with the #THRESH_BINARY and #THRESH_BINARY_INV thresholding\n",
      "    .   types.\n",
      "    .   @param type thresholding type (see #ThresholdTypes).\n",
      "    .   @return the computed threshold value if Otsu's or Triangle methods used.\n",
      "    .   \n",
      "    .   @sa  adaptiveThreshold, findContours, compare, min, max\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the image\n",
    "base = '/mnt/c/Users/Михаил/Documents/IITP/ImgProc/Pics/'\n",
    "im = cv2.imread(base + 'skyscraper2.jpg')\n",
    "gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "equ = cv2.equalizeHist(gray)\n",
    "#ret, thresh = cv2.threshold(equ,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "winSize = 7\n",
    "blured = cv2.GaussianBlur(equ, (winSize, winSize), 0)\n",
    "edges = cv2.Canny(blured,100,220,apertureSize = 7, L2gradient=True)\n",
    "\n",
    "\n",
    "\n",
    "#cv2.imshow('houghlines',im)\n",
    "cv2.imwrite(base+'gray.jpg', gray)\n",
    "cv2.imwrite(base+'equ.jpg', equ)\n",
    "cv2.imwrite(base+'blured.jpg', blured)\n",
    "cv2.imwrite(base+'edges.jpg', edges)\n",
    "\n",
    "#cv2.imwrite(base+'thresh.jpg', thresh)\n",
    "\n",
    "#A few changes to check git functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function Canny:\n",
      "\n",
      "Canny(...)\n",
      "    Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]) -> edges\n",
      "    .   @brief Finds edges in an image using the Canny algorithm @cite Canny86 .\n",
      "    .   \n",
      "    .   The function finds edges in the input image and marks them in the output map edges using the\n",
      "    .   Canny algorithm. The smallest value between threshold1 and threshold2 is used for edge linking. The\n",
      "    .   largest value is used to find initial segments of strong edges. See\n",
      "    .   <http://en.wikipedia.org/wiki/Canny_edge_detector>\n",
      "    .   \n",
      "    .   @param image 8-bit input image.\n",
      "    .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
      "    .   @param threshold1 first threshold for the hysteresis procedure.\n",
      "    .   @param threshold2 second threshold for the hysteresis procedure.\n",
      "    .   @param apertureSize aperture size for the Sobel operator.\n",
      "    .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "    .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
      "    .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
      "    .   L2gradient=false ).\n",
      "    \n",
      "    \n",
      "    \n",
      "    Canny(dx, dy, threshold1, threshold2[, edges[, L2gradient]]) -> edges\n",
      "    .   \\overload\n",
      "    .   \n",
      "    .   Finds edges in an image using the Canny algorithm with custom image gradient.\n",
      "    .   \n",
      "    .   @param dx 16-bit x derivative of input image (CV_16SC1 or CV_16SC3).\n",
      "    .   @param dy 16-bit y derivative of input image (same type as dx).\n",
      "    .   @param edges output edge map; single channels 8-bit image, which has the same size as image .\n",
      "    .   @param threshold1 first threshold for the hysteresis procedure.\n",
      "    .   @param threshold2 second threshold for the hysteresis procedure.\n",
      "    .   @param L2gradient a flag, indicating whether a more accurate \\f$L_2\\f$ norm\n",
      "    .   \\f$=\\sqrt{(dI/dx)^2 + (dI/dy)^2}\\f$ should be used to calculate the image gradient magnitude (\n",
      "    .   L2gradient=true ), or whether the default \\f$L_1\\f$ norm \\f$=|dI/dx|+|dI/dy|\\f$ is enough (\n",
      "    .   L2gradient=false ).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.Canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function HoughLines:\n",
      "\n",
      "HoughLines(...)\n",
      "    HoughLines(image, rho, theta, threshold[, lines[, srn[, stn[, min_theta[, max_theta]]]]]) -> lines\n",
      "    .   @brief Finds lines in a binary image using the standard Hough transform.\n",
      "    .   \n",
      "    .   The function implements the standard or standard multi-scale Hough transform algorithm for line\n",
      "    .   detection. See <http://homepages.inf.ed.ac.uk/rbf/HIPR2/hough.htm> for a good explanation of Hough\n",
      "    .   transform.\n",
      "    .   \n",
      "    .   @param image 8-bit, single-channel binary source image. The image may be modified by the function.\n",
      "    .   @param lines Output vector of lines. Each line is represented by a two-element vector\n",
      "    .   \\f$(\\rho, \\theta)\\f$ . \\f$\\rho\\f$ is the distance from the coordinate origin \\f$(0,0)\\f$ (top-left corner of\n",
      "    .   the image). \\f$\\theta\\f$ is the line rotation angle in radians (\n",
      "    .   \\f$0 \\sim \\textrm{vertical line}, \\pi/2 \\sim \\textrm{horizontal line}\\f$ ).\n",
      "    .   @param rho Distance resolution of the accumulator in pixels.\n",
      "    .   @param theta Angle resolution of the accumulator in radians.\n",
      "    .   @param threshold Accumulator threshold parameter. Only those lines are returned that get enough\n",
      "    .   votes ( \\f$>\\texttt{threshold}\\f$ ).\n",
      "    .   @param srn For the multi-scale Hough transform, it is a divisor for the distance resolution rho .\n",
      "    .   The coarse accumulator distance resolution is rho and the accurate accumulator resolution is\n",
      "    .   rho/srn . If both srn=0 and stn=0 , the classical Hough transform is used. Otherwise, both these\n",
      "    .   parameters should be positive.\n",
      "    .   @param stn For the multi-scale Hough transform, it is a divisor for the distance resolution theta.\n",
      "    .   @param min_theta For standard and multi-scale Hough transform, minimum angle to check for lines.\n",
      "    .   Must fall between 0 and max_theta.\n",
      "    .   @param max_theta For standard and multi-scale Hough transform, maximum angle to check for lines.\n",
      "    .   Must fall between min_theta and CV_PI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.HoughLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 360, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line (img, rho, theta, color=(0,255,0)):\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))   # Here i have used int() instead of rounding the decimal value, so 3.8 --> 3\n",
    "    y1 = int(y0 + 1000*(a))    # But if you want to round the number, then use np.around() function, then 3.8 --> 4.0\n",
    "    x2 = int(x0 - 1000*(-b))   # But we need integers, so use int() function after that, ie int(np.around(x))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),color,2)\n",
    "    print (rho, theta, color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5707963267948966"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pi / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.0 2.1642082 (0, 255, 0)\n",
      "234.0 1.5707964 (0, 255, 0)\n",
      "-169.0 2.687807 (0, 255, 0)\n",
      "193.0 0.9599311 (0, 255, 0)\n",
      "210.0 1.5707964 (0, 255, 0)\n",
      "228.0 1.5707964 (0, 255, 0)\n",
      "129.0 0.715585 (0, 255, 0)\n",
      "197.0 1.5707964 (0, 255, 0)\n",
      "-143.0 2.443461 (0, 255, 0)\n",
      "201.0 1.5707964 (0, 255, 0)\n",
      "223.0 1.5707964 (0, 255, 0)\n",
      "154.0 0.4537856 (0, 255, 0)\n",
      "174.0 1.553343 (0, 255, 0)\n",
      "245.0 1.5707964 (0, 255, 0)\n",
      "185.0 1.553343 (0, 255, 0)\n",
      "265.0 1.5707964 (0, 255, 0)\n",
      "-142.0 2.4609141 (0, 255, 0)\n",
      "197.0 0.94247776 (0, 255, 0)\n",
      "171.0 1.5707964 (0, 255, 0)\n",
      "159.0 1.553343 (0, 255, 0)\n",
      "181.0 1.553343 (0, 255, 0)\n",
      "178.0 1.5707964 (0, 255, 0)\n",
      "-165.0 2.687807 (0, 255, 0)\n",
      "189.0 1.5707964 (0, 255, 0)\n",
      "245.0 0.7853982 (0, 255, 0)\n",
      "-49.0 2.3561945 (0, 255, 0)\n",
      "-6.0 2.3561945 (0, 255, 0)\n",
      "152.0 1.553343 (0, 255, 0)\n",
      "-132.0 2.4085543 (0, 255, 0)\n",
      "-169.0 2.687807 (0, 0, 255)\n",
      "129.0 0.715585 (0, 0, 255)\n",
      "171.0 1.5707963267948966 (0, 0, 255)\n",
      "265.0 1.5707963267948966 (0, 0, 255)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = im.copy()\n",
    "rho_minus = 0\n",
    "rho_plus = np.inf\n",
    "rho_hor_max = 0\n",
    "rho_hor_min = np.inf\n",
    "eps = 0.01\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180, int (min(im.shape[0], im.shape[1]) / 2))\n",
    "#print (lines)\n",
    "for line in lines:\n",
    "    for rho,theta in line:\n",
    "        if (theta > np.pi / 2 + eps and np.abs (rho) > np.abs (rho_minus)):\n",
    "            rho_minus = rho\n",
    "            theta_minus = theta\n",
    "        if (theta < np.pi / 2 - eps and rho < rho_plus):\n",
    "            rho_plus = rho\n",
    "            theta_plus = theta\n",
    "        if (np.abs (theta - np.pi / 2) < eps):\n",
    "            if (rho > rho_hor_max):\n",
    "                rho_hor_max = rho\n",
    "            if (rho < rho_hor_min):\n",
    "                rho_hor_min = rho\n",
    "        draw_line (img, rho, theta)\n",
    "red = (0, 0, 255)\n",
    "draw_line (img, rho_minus, theta_minus, red)\n",
    "draw_line (img, rho_plus, theta_plus, red)\n",
    "draw_line (img, rho_hor_min, np.pi / 2, red)\n",
    "draw_line (img, rho_hor_max, np.pi / 2, red)\n",
    "cv2.imwrite(base+'houghlines.jpg', img)\n",
    "#cv2.imshow('houghlines',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = im.copy()\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,80, minLineLength = 100, maxLineGap = 10)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "cv2.imwrite(base+'houghlines_p.jpg', img)\n",
    "#cv2.imshow('houghlines',img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
